{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "\n",
    "import register_widerface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python register_widerface.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /home/idealabs/Libs/miniconda3/envs/.torchenv/lib/python3.7/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/retinanet_R_50_FPN_1x.yaml'))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_50_FPN_1x.yaml\")\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"widerface_train\",)\n",
    "cfg.DATASETS.TEST = (\"widerface_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.MAX_ITER = 1500\n",
    "cfg.SOLVER.STEPS = (1000, 1500)\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 1\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "\n",
    "    if output_folder is None:\n",
    "        os.makedirs(\"wider_eval\", exist_ok=True)\n",
    "        output_folder = \"wider_eval\"\n",
    "\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/18 17:11:35 d2.engine.defaults]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/18 17:11:36 d2.data.datasets.coco]: \u001b[0mLoaded 12880 images in COCO format from /home/idealabs/data/opensource_dataset/WIDER/widerface_train_coco.json\n",
      "\u001b[32m[12/18 17:11:37 d2.data.build]: \u001b[0mRemoved 4 images with no usable annotations. 12876 images left.\n",
      "\u001b[32m[12/18 17:11:37 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    face    | 159420       |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[12/18 17:11:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/18 17:11:37 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/18 17:11:37 d2.data.common]: \u001b[0mSerializing 12876 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/18 17:11:37 d2.data.common]: \u001b[0mSerialized dataset takes 12.31 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'head.cls_score.weight' to the model due to incompatible shapes: (720, 256, 3, 3) in the checkpoint but (9, 256, 3, 3) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'head.cls_score.bias' to the model due to incompatible shapes: (720,) in the checkpoint but (9,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/18 17:11:37 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[12/18 17:11:47 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 19  total_loss: 2.326  loss_cls: 1.43  loss_box_reg: 0.8959  time: 0.4691  data_time: 0.0163  lr: 1.9981e-05  max_mem: 4625M\n",
      "\u001b[32m[12/18 17:11:55 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 39  total_loss: 1.293  loss_cls: 0.6878  loss_box_reg: 0.6069  time: 0.4402  data_time: 0.0047  lr: 3.9961e-05  max_mem: 4625M\n",
      "\u001b[32m[12/18 17:12:04 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 59  total_loss: 1.358  loss_cls: 0.7424  loss_box_reg: 0.6313  time: 0.4453  data_time: 0.0047  lr: 5.9941e-05  max_mem: 4990M\n",
      "\u001b[32m[12/18 17:12:14 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 79  total_loss: 0.8775  loss_cls: 0.5054  loss_box_reg: 0.3721  time: 0.4435  data_time: 0.0049  lr: 7.9921e-05  max_mem: 7800M\n",
      "\u001b[32m[12/18 17:12:23 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 99  total_loss: 0.7789  loss_cls: 0.4407  loss_box_reg: 0.3186  time: 0.4386  data_time: 0.0052  lr: 9.9901e-05  max_mem: 7800M\n",
      "\u001b[32m[12/18 17:12:32 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 119  total_loss: 0.9248  loss_cls: 0.477  loss_box_reg: 0.4479  time: 0.4391  data_time: 0.0046  lr: 0.00011988  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:12:41 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 139  total_loss: 0.7683  loss_cls: 0.4175  loss_box_reg: 0.3508  time: 0.4373  data_time: 0.0058  lr: 0.00013986  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:12:50 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 159  total_loss: 0.941  loss_cls: 0.4369  loss_box_reg: 0.5448  time: 0.4371  data_time: 0.0046  lr: 0.00015984  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:12:59 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 179  total_loss: 0.7746  loss_cls: 0.355  loss_box_reg: 0.3611  time: 0.4403  data_time: 0.0046  lr: 0.00017982  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:13:08 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 199  total_loss: 0.5496  loss_cls: 0.2679  loss_box_reg: 0.2988  time: 0.4420  data_time: 0.0047  lr: 0.0001998  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:13:18 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 219  total_loss: 0.7692  loss_cls: 0.3281  loss_box_reg: 0.4091  time: 0.4433  data_time: 0.0049  lr: 0.00021978  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:13:27 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 239  total_loss: 0.7418  loss_cls: 0.334  loss_box_reg: 0.3935  time: 0.4455  data_time: 0.0046  lr: 0.00023976  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:13:36 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 259  total_loss: 0.7452  loss_cls: 0.3423  loss_box_reg: 0.4029  time: 0.4468  data_time: 0.0047  lr: 0.00025974  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:13:45 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 279  total_loss: 0.6499  loss_cls: 0.2826  loss_box_reg: 0.3673  time: 0.4462  data_time: 0.0051  lr: 0.00027972  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:13:54 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 299  total_loss: 0.5665  loss_cls: 0.242  loss_box_reg: 0.3245  time: 0.4460  data_time: 0.0049  lr: 0.0002997  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:14:03 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 319  total_loss: 0.5646  loss_cls: 0.2285  loss_box_reg: 0.3249  time: 0.4464  data_time: 0.0056  lr: 0.00031968  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:14:12 d2.utils.events]: \u001b[0m eta: 0:08:41  iter: 339  total_loss: 0.4605  loss_cls: 0.2047  loss_box_reg: 0.2462  time: 0.4469  data_time: 0.0051  lr: 0.00033966  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:14:21 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 359  total_loss: 0.4613  loss_cls: 0.2126  loss_box_reg: 0.2487  time: 0.4469  data_time: 0.0046  lr: 0.00035964  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:14:30 d2.utils.events]: \u001b[0m eta: 0:08:23  iter: 379  total_loss: 0.3305  loss_cls: 0.1469  loss_box_reg: 0.1827  time: 0.4476  data_time: 0.0048  lr: 0.00037962  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:14:39 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 399  total_loss: 0.651  loss_cls: 0.2134  loss_box_reg: 0.4166  time: 0.4472  data_time: 0.0047  lr: 0.0003996  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:14:48 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 419  total_loss: 0.3661  loss_cls: 0.1574  loss_box_reg: 0.2105  time: 0.4466  data_time: 0.0048  lr: 0.00041958  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:14:57 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 439  total_loss: 0.563  loss_cls: 0.239  loss_box_reg: 0.324  time: 0.4472  data_time: 0.0048  lr: 0.00043956  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:15:06 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 459  total_loss: 0.5531  loss_cls: 0.228  loss_box_reg: 0.3251  time: 0.4465  data_time: 0.0055  lr: 0.00045954  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:15:15 d2.utils.events]: \u001b[0m eta: 0:07:38  iter: 479  total_loss: 0.5013  loss_cls: 0.2106  loss_box_reg: 0.2929  time: 0.4460  data_time: 0.0048  lr: 0.00047952  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:15:24 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 499  total_loss: 0.5858  loss_cls: 0.2461  loss_box_reg: 0.3367  time: 0.4465  data_time: 0.0046  lr: 0.0004995  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:15:33 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 519  total_loss: 0.3756  loss_cls: 0.1432  loss_box_reg: 0.2093  time: 0.4467  data_time: 0.0046  lr: 0.00051948  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:15:42 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 539  total_loss: 0.5472  loss_cls: 0.1962  loss_box_reg: 0.317  time: 0.4468  data_time: 0.0049  lr: 0.00053946  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:15:51 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 559  total_loss: 0.351  loss_cls: 0.1474  loss_box_reg: 0.2061  time: 0.4467  data_time: 0.0048  lr: 0.00055944  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:16:01 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 579  total_loss: 0.2428  loss_cls: 0.1142  loss_box_reg: 0.139  time: 0.4478  data_time: 0.0048  lr: 0.00057942  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:16:10 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 599  total_loss: 0.5172  loss_cls: 0.2175  loss_box_reg: 0.2733  time: 0.4481  data_time: 0.0046  lr: 0.0005994  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:16:19 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 619  total_loss: 0.4998  loss_cls: 0.2052  loss_box_reg: 0.2976  time: 0.4475  data_time: 0.0052  lr: 0.00061938  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:16:28 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 639  total_loss: 0.4921  loss_cls: 0.2071  loss_box_reg: 0.2842  time: 0.4482  data_time: 0.0049  lr: 0.00063936  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:16:37 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 659  total_loss: 0.4233  loss_cls: 0.1746  loss_box_reg: 0.2481  time: 0.4484  data_time: 0.0046  lr: 0.00065934  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:16:47 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 679  total_loss: 0.5638  loss_cls: 0.2473  loss_box_reg: 0.3032  time: 0.4482  data_time: 0.0058  lr: 0.00067932  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:16:55 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 699  total_loss: 0.3527  loss_cls: 0.1434  loss_box_reg: 0.1916  time: 0.4479  data_time: 0.0048  lr: 0.0006993  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:17:05 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 719  total_loss: 0.4152  loss_cls: 0.1776  loss_box_reg: 0.2237  time: 0.4475  data_time: 0.0054  lr: 0.00071928  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:17:14 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 739  total_loss: 0.493  loss_cls: 0.1973  loss_box_reg: 0.3185  time: 0.4477  data_time: 0.0046  lr: 0.00073926  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:17:23 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 759  total_loss: 0.4539  loss_cls: 0.1551  loss_box_reg: 0.2866  time: 0.4475  data_time: 0.0047  lr: 0.00075924  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:17:32 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 779  total_loss: 0.5652  loss_cls: 0.2853  loss_box_reg: 0.2706  time: 0.4476  data_time: 0.0047  lr: 0.00077922  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:17:42 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 799  total_loss: 0.5609  loss_cls: 0.2703  loss_box_reg: 0.2906  time: 0.4475  data_time: 0.0046  lr: 0.0007992  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:17:51 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 819  total_loss: 0.5811  loss_cls: 0.2257  loss_box_reg: 0.3509  time: 0.4473  data_time: 0.0048  lr: 0.00081918  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:18:00 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 839  total_loss: 0.5183  loss_cls: 0.2185  loss_box_reg: 0.3144  time: 0.4472  data_time: 0.0047  lr: 0.00083916  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:18:09 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 859  total_loss: 0.4415  loss_cls: 0.2334  loss_box_reg: 0.2201  time: 0.4478  data_time: 0.0047  lr: 0.00085914  max_mem: 9169M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/18 17:18:19 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 879  total_loss: 0.4912  loss_cls: 0.2502  loss_box_reg: 0.2477  time: 0.4483  data_time: 0.0049  lr: 0.00087912  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:18:28 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 899  total_loss: 0.3715  loss_cls: 0.1562  loss_box_reg: 0.2019  time: 0.4486  data_time: 0.0047  lr: 0.0008991  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:18:37 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 919  total_loss: 0.4424  loss_cls: 0.1487  loss_box_reg: 0.2959  time: 0.4485  data_time: 0.0047  lr: 0.00091908  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:18:46 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 939  total_loss: 0.38  loss_cls: 0.1268  loss_box_reg: 0.2532  time: 0.4487  data_time: 0.0045  lr: 0.00093906  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:18:55 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 959  total_loss: 0.4985  loss_cls: 0.208  loss_box_reg: 0.282  time: 0.4487  data_time: 0.0050  lr: 0.00095904  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:19:04 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 979  total_loss: 0.3236  loss_cls: 0.1295  loss_box_reg: 0.1841  time: 0.4484  data_time: 0.0047  lr: 0.00097902  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:19:13 d2.data.datasets.coco]: \u001b[0mLoaded 3222 images in COCO format from /home/idealabs/data/opensource_dataset/WIDER/widerface_val_coco.json\n",
      "\u001b[32m[12/18 17:19:13 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    face    | 39704        |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[12/18 17:19:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/18 17:19:13 d2.data.common]: \u001b[0mSerializing 3222 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/18 17:19:13 d2.data.common]: \u001b[0mSerialized dataset takes 3.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/18 17:19:13 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[12/18 17:19:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 3222 images\n",
      "\u001b[32m[12/18 17:19:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/3222. 0.0533 s / img. ETA=0:02:53\n",
      "\u001b[32m[12/18 17:19:19 d2.evaluation.evaluator]: \u001b[0mInference done 109/3222. 0.0506 s / img. ETA=0:02:40\n",
      "\u001b[32m[12/18 17:19:24 d2.evaluation.evaluator]: \u001b[0mInference done 205/3222. 0.0507 s / img. ETA=0:02:36\n",
      "\u001b[32m[12/18 17:19:29 d2.evaluation.evaluator]: \u001b[0mInference done 300/3222. 0.0512 s / img. ETA=0:02:32\n",
      "\u001b[32m[12/18 17:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 397/3222. 0.0511 s / img. ETA=0:02:27\n",
      "\u001b[32m[12/18 17:19:39 d2.evaluation.evaluator]: \u001b[0mInference done 494/3222. 0.0510 s / img. ETA=0:02:22\n",
      "\u001b[32m[12/18 17:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 590/3222. 0.0511 s / img. ETA=0:02:17\n",
      "\u001b[32m[12/18 17:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 687/3222. 0.0511 s / img. ETA=0:02:12\n",
      "\u001b[32m[12/18 17:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 784/3222. 0.0510 s / img. ETA=0:02:06\n",
      "\u001b[32m[12/18 17:19:59 d2.evaluation.evaluator]: \u001b[0mInference done 878/3222. 0.0512 s / img. ETA=0:02:02\n",
      "\u001b[32m[12/18 17:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 972/3222. 0.0513 s / img. ETA=0:01:57\n",
      "\u001b[32m[12/18 17:20:09 d2.evaluation.evaluator]: \u001b[0mInference done 1065/3222. 0.0515 s / img. ETA=0:01:53\n",
      "\u001b[32m[12/18 17:20:14 d2.evaluation.evaluator]: \u001b[0mInference done 1156/3222. 0.0517 s / img. ETA=0:01:48\n",
      "\u001b[32m[12/18 17:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 1250/3222. 0.0518 s / img. ETA=0:01:44\n",
      "\u001b[32m[12/18 17:20:25 d2.evaluation.evaluator]: \u001b[0mInference done 1344/3222. 0.0518 s / img. ETA=0:01:39\n",
      "\u001b[32m[12/18 17:20:30 d2.evaluation.evaluator]: \u001b[0mInference done 1439/3222. 0.0517 s / img. ETA=0:01:34\n",
      "\u001b[32m[12/18 17:20:35 d2.evaluation.evaluator]: \u001b[0mInference done 1541/3222. 0.0515 s / img. ETA=0:01:28\n",
      "\u001b[32m[12/18 17:20:40 d2.evaluation.evaluator]: \u001b[0mInference done 1639/3222. 0.0514 s / img. ETA=0:01:23\n",
      "\u001b[32m[12/18 17:20:45 d2.evaluation.evaluator]: \u001b[0mInference done 1736/3222. 0.0514 s / img. ETA=0:01:17\n",
      "\u001b[32m[12/18 17:20:50 d2.evaluation.evaluator]: \u001b[0mInference done 1833/3222. 0.0514 s / img. ETA=0:01:12\n",
      "\u001b[32m[12/18 17:20:55 d2.evaluation.evaluator]: \u001b[0mInference done 1932/3222. 0.0513 s / img. ETA=0:01:07\n",
      "\u001b[32m[12/18 17:21:00 d2.evaluation.evaluator]: \u001b[0mInference done 2028/3222. 0.0513 s / img. ETA=0:01:02\n",
      "\u001b[32m[12/18 17:21:05 d2.evaluation.evaluator]: \u001b[0mInference done 2123/3222. 0.0513 s / img. ETA=0:00:57\n",
      "\u001b[32m[12/18 17:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 2220/3222. 0.0513 s / img. ETA=0:00:52\n",
      "\u001b[32m[12/18 17:21:15 d2.evaluation.evaluator]: \u001b[0mInference done 2316/3222. 0.0513 s / img. ETA=0:00:47\n",
      "\u001b[32m[12/18 17:21:20 d2.evaluation.evaluator]: \u001b[0mInference done 2410/3222. 0.0513 s / img. ETA=0:00:42\n",
      "\u001b[32m[12/18 17:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 2505/3222. 0.0513 s / img. ETA=0:00:37\n",
      "\u001b[32m[12/18 17:21:30 d2.evaluation.evaluator]: \u001b[0mInference done 2602/3222. 0.0513 s / img. ETA=0:00:32\n",
      "\u001b[32m[12/18 17:21:35 d2.evaluation.evaluator]: \u001b[0mInference done 2698/3222. 0.0513 s / img. ETA=0:00:27\n",
      "\u001b[32m[12/18 17:21:40 d2.evaluation.evaluator]: \u001b[0mInference done 2794/3222. 0.0513 s / img. ETA=0:00:22\n",
      "\u001b[32m[12/18 17:21:45 d2.evaluation.evaluator]: \u001b[0mInference done 2891/3222. 0.0513 s / img. ETA=0:00:17\n",
      "\u001b[32m[12/18 17:21:50 d2.evaluation.evaluator]: \u001b[0mInference done 2988/3222. 0.0513 s / img. ETA=0:00:12\n",
      "\u001b[32m[12/18 17:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 3086/3222. 0.0513 s / img. ETA=0:00:07\n",
      "\u001b[32m[12/18 17:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 3181/3222. 0.0513 s / img. ETA=0:00:02\n",
      "\u001b[32m[12/18 17:22:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:48.304716 (0.052317 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/18 17:22:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:44 (0.051269 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/18 17:22:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/18 17:22:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to wider_eval/coco_instances_results.json\n",
      "\u001b[32m[12/18 17:22:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 1.48 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.40 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.451\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.555\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n",
      "\u001b[32m[12/18 17:22:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.031 | 45.125 | 19.694 | 10.646 | 47.567 | 55.633 |\n",
      "\u001b[32m[12/18 17:22:07 d2.engine.defaults]: \u001b[0mEvaluation results for widerface_val in csv format:\n",
      "\u001b[32m[12/18 17:22:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[12/18 17:22:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/18 17:22:07 d2.evaluation.testing]: \u001b[0mcopypaste: 22.0314,45.1254,19.6937,10.6459,47.5675,55.6327\n",
      "\u001b[32m[12/18 17:22:07 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 999  total_loss: 0.4607  loss_cls: 0.1725  loss_box_reg: 0.2944  time: 0.4485  data_time: 0.0050  lr: 0.000999  max_mem: 9169M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/18 17:22:16 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 1019  total_loss: 0.3223  loss_cls: 0.1236  loss_box_reg: 0.1987  time: 0.4484  data_time: 0.0055  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:22:25 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 1039  total_loss: 0.327  loss_cls: 0.1292  loss_box_reg: 0.2137  time: 0.4486  data_time: 0.0047  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:22:34 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 1059  total_loss: 0.318  loss_cls: 0.1193  loss_box_reg: 0.1988  time: 0.4479  data_time: 0.0051  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:22:43 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 1079  total_loss: 0.4284  loss_cls: 0.1256  loss_box_reg: 0.2628  time: 0.4476  data_time: 0.0050  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:22:52 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 1099  total_loss: 0.3765  loss_cls: 0.1437  loss_box_reg: 0.2302  time: 0.4479  data_time: 0.0059  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:23:01 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 1119  total_loss: 0.3388  loss_cls: 0.1335  loss_box_reg: 0.1992  time: 0.4477  data_time: 0.0049  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:23:10 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 1139  total_loss: 0.3825  loss_cls: 0.1335  loss_box_reg: 0.2414  time: 0.4477  data_time: 0.0050  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:23:19 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 1159  total_loss: 0.2871  loss_cls: 0.09097  loss_box_reg: 0.1774  time: 0.4476  data_time: 0.0047  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:23:29 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 1179  total_loss: 0.3375  loss_cls: 0.1285  loss_box_reg: 0.2086  time: 0.4475  data_time: 0.0066  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:23:38 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 1199  total_loss: 0.3799  loss_cls: 0.1448  loss_box_reg: 0.2259  time: 0.4476  data_time: 0.0048  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:23:47 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 1219  total_loss: 0.4148  loss_cls: 0.1455  loss_box_reg: 0.2595  time: 0.4478  data_time: 0.0047  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:23:56 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 1239  total_loss: 0.4758  loss_cls: 0.175  loss_box_reg: 0.2949  time: 0.4478  data_time: 0.0047  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:24:05 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 1259  total_loss: 0.3143  loss_cls: 0.1159  loss_box_reg: 0.197  time: 0.4480  data_time: 0.0047  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:24:15 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 1279  total_loss: 0.4431  loss_cls: 0.186  loss_box_reg: 0.2557  time: 0.4483  data_time: 0.0048  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:24:24 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 1299  total_loss: 0.2957  loss_cls: 0.09846  loss_box_reg: 0.1896  time: 0.4478  data_time: 0.0056  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:24:32 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 1319  total_loss: 0.2413  loss_cls: 0.08644  loss_box_reg: 0.158  time: 0.4476  data_time: 0.0047  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:24:41 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 1339  total_loss: 0.3702  loss_cls: 0.1534  loss_box_reg: 0.2412  time: 0.4475  data_time: 0.0049  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:24:51 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 1359  total_loss: 0.3484  loss_cls: 0.1269  loss_box_reg: 0.2215  time: 0.4478  data_time: 0.0047  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:25:00 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 1379  total_loss: 0.5619  loss_cls: 0.2338  loss_box_reg: 0.346  time: 0.4479  data_time: 0.0048  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:25:09 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 1399  total_loss: 0.3169  loss_cls: 0.1416  loss_box_reg: 0.2033  time: 0.4477  data_time: 0.0052  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:25:17 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 1419  total_loss: 0.4202  loss_cls: 0.1723  loss_box_reg: 0.2575  time: 0.4476  data_time: 0.0046  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:25:27 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 1439  total_loss: 0.314  loss_cls: 0.1084  loss_box_reg: 0.2003  time: 0.4477  data_time: 0.0062  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:25:36 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 1459  total_loss: 0.4185  loss_cls: 0.1563  loss_box_reg: 0.2429  time: 0.4476  data_time: 0.0048  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:25:45 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 1479  total_loss: 0.375  loss_cls: 0.1461  loss_box_reg: 0.2555  time: 0.4479  data_time: 0.0049  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:25:55 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.3222  loss_cls: 0.1141  loss_box_reg: 0.2254  time: 0.4478  data_time: 0.0048  lr: 5e-05  max_mem: 9169M\n",
      "\u001b[32m[12/18 17:25:56 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:11:10 (0.4478 s / it)\n",
      "\u001b[32m[12/18 17:25:56 d2.engine.hooks]: \u001b[0mTotal training time: 0:14:17 (0:03:07 on hooks)\n",
      "\u001b[32m[12/18 17:25:57 d2.data.datasets.coco]: \u001b[0mLoaded 3222 images in COCO format from /home/idealabs/data/opensource_dataset/WIDER/widerface_val_coco.json\n",
      "\u001b[32m[12/18 17:25:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/18 17:25:57 d2.data.common]: \u001b[0mSerializing 3222 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/18 17:25:57 d2.data.common]: \u001b[0mSerialized dataset takes 3.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/18 17:25:57 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[12/18 17:25:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 3222 images\n",
      "\u001b[32m[12/18 17:25:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/3222. 0.0506 s / img. ETA=0:02:46\n",
      "\u001b[32m[12/18 17:26:03 d2.evaluation.evaluator]: \u001b[0mInference done 109/3222. 0.0496 s / img. ETA=0:02:39\n",
      "\u001b[32m[12/18 17:26:08 d2.evaluation.evaluator]: \u001b[0mInference done 207/3222. 0.0499 s / img. ETA=0:02:34\n",
      "\u001b[32m[12/18 17:26:13 d2.evaluation.evaluator]: \u001b[0mInference done 304/3222. 0.0503 s / img. ETA=0:02:30\n",
      "\u001b[32m[12/18 17:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 402/3222. 0.0503 s / img. ETA=0:02:25\n",
      "\u001b[32m[12/18 17:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 499/3222. 0.0504 s / img. ETA=0:02:20\n",
      "\u001b[32m[12/18 17:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 593/3222. 0.0507 s / img. ETA=0:02:16\n",
      "\u001b[32m[12/18 17:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 689/3222. 0.0508 s / img. ETA=0:02:11\n",
      "\u001b[32m[12/18 17:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 786/3222. 0.0508 s / img. ETA=0:02:06\n",
      "\u001b[32m[12/18 17:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 882/3222. 0.0509 s / img. ETA=0:02:01\n",
      "\u001b[32m[12/18 17:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 979/3222. 0.0509 s / img. ETA=0:01:56\n",
      "\u001b[32m[12/18 17:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 1076/3222. 0.0509 s / img. ETA=0:01:51\n",
      "\u001b[32m[12/18 17:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 1171/3222. 0.0510 s / img. ETA=0:01:46\n",
      "\u001b[32m[12/18 17:27:03 d2.evaluation.evaluator]: \u001b[0mInference done 1268/3222. 0.0510 s / img. ETA=0:01:41\n",
      "\u001b[32m[12/18 17:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 1364/3222. 0.0510 s / img. ETA=0:01:36\n",
      "\u001b[32m[12/18 17:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 1460/3222. 0.0510 s / img. ETA=0:01:31\n",
      "\u001b[32m[12/18 17:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 1563/3222. 0.0508 s / img. ETA=0:01:25\n",
      "\u001b[32m[12/18 17:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 1660/3222. 0.0508 s / img. ETA=0:01:20\n",
      "\u001b[32m[12/18 17:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 1758/3222. 0.0508 s / img. ETA=0:01:15\n",
      "\u001b[32m[12/18 17:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 1855/3222. 0.0508 s / img. ETA=0:01:10\n",
      "\u001b[32m[12/18 17:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 1950/3222. 0.0508 s / img. ETA=0:01:05\n",
      "\u001b[32m[12/18 17:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 2040/3222. 0.0510 s / img. ETA=0:01:01\n",
      "\u001b[32m[12/18 17:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 2134/3222. 0.0511 s / img. ETA=0:00:56\n",
      "\u001b[32m[12/18 17:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 2231/3222. 0.0511 s / img. ETA=0:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/18 17:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 2329/3222. 0.0510 s / img. ETA=0:00:46\n",
      "\u001b[32m[12/18 17:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 2423/3222. 0.0511 s / img. ETA=0:00:41\n",
      "\u001b[32m[12/18 17:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 2520/3222. 0.0511 s / img. ETA=0:00:36\n",
      "\u001b[32m[12/18 17:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 2618/3222. 0.0511 s / img. ETA=0:00:31\n",
      "\u001b[32m[12/18 17:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 2716/3222. 0.0510 s / img. ETA=0:00:26\n",
      "\u001b[32m[12/18 17:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 2812/3222. 0.0511 s / img. ETA=0:00:21\n",
      "\u001b[32m[12/18 17:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 2908/3222. 0.0511 s / img. ETA=0:00:16\n",
      "\u001b[32m[12/18 17:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 3004/3222. 0.0511 s / img. ETA=0:00:11\n",
      "\u001b[32m[12/18 17:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 3097/3222. 0.0512 s / img. ETA=0:00:06\n",
      "\u001b[32m[12/18 17:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 3190/3222. 0.0512 s / img. ETA=0:00:01\n",
      "\u001b[32m[12/18 17:28:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:47.844003 (0.052174 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/18 17:28:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:44 (0.051192 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/18 17:28:46 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/18 17:28:46 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to wider_eval/coco_instances_results.json\n",
      "\u001b[32m[12/18 17:28:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.47s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 1.47 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.39 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.460\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.515\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.581\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675\n",
      "\u001b[32m[12/18 17:28:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.523 | 46.041 | 22.137 | 10.922 | 51.480 | 60.463 |\n",
      "\u001b[32m[12/18 17:28:49 d2.engine.defaults]: \u001b[0mEvaluation results for widerface_val in csv format:\n",
      "\u001b[32m[12/18 17:28:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[12/18 17:28:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/18 17:28:49 d2.evaluation.testing]: \u001b[0mcopypaste: 23.5235,46.0414,22.1366,10.9221,51.4803,60.4630\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "trainer = CocoTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco_instances_results.json\r\n",
      "events.out.tfevents.1608275887.ubuntu.12790.0\r\n",
      "events.out.tfevents.1608275996.ubuntu.12790.1\r\n",
      "events.out.tfevents.1608277171.ubuntu.17549.0\r\n",
      "events.out.tfevents.1608277211.ubuntu.17714.0\r\n",
      "events.out.tfevents.1608280190.ubuntu.17714.1\r\n",
      "events.out.tfevents.1608281006.ubuntu.17714.2\r\n",
      "events.out.tfevents.1608282354.ubuntu.17714.3\r\n",
      "events.out.tfevents.1608282697.ubuntu.7911.0\r\n",
      "instances_predictions.pth\r\n",
      "last_checkpoint\r\n",
      "metrics.json\r\n",
      "model_final.pth\r\n"
     ]
    }
   ],
   "source": [
    "ls output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/18 17:28:51 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[12/18 17:28:51 d2.data.datasets.coco]: \u001b[0mLoaded 3222 images in COCO format from /home/idealabs/data/opensource_dataset/WIDER/widerface_val_coco.json\n",
      "\u001b[32m[12/18 17:28:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/18 17:28:51 d2.data.common]: \u001b[0mSerializing 3222 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/18 17:28:51 d2.data.common]: \u001b[0mSerialized dataset takes 3.06 MiB\n",
      "\u001b[32m[12/18 17:28:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 3222 images\n",
      "\u001b[32m[12/18 17:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/3222. 0.0509 s / img. ETA=0:02:45\n",
      "\u001b[32m[12/18 17:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 108/3222. 0.0510 s / img. ETA=0:02:41\n",
      "\u001b[32m[12/18 17:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 206/3222. 0.0507 s / img. ETA=0:02:35\n",
      "\u001b[32m[12/18 17:29:07 d2.evaluation.evaluator]: \u001b[0mInference done 303/3222. 0.0508 s / img. ETA=0:02:30\n",
      "\u001b[32m[12/18 17:29:12 d2.evaluation.evaluator]: \u001b[0mInference done 402/3222. 0.0505 s / img. ETA=0:02:25\n",
      "\u001b[32m[12/18 17:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 499/3222. 0.0506 s / img. ETA=0:02:20\n",
      "\u001b[32m[12/18 17:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 597/3222. 0.0506 s / img. ETA=0:02:15\n",
      "\u001b[32m[12/18 17:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 696/3222. 0.0505 s / img. ETA=0:02:09\n",
      "\u001b[32m[12/18 17:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 793/3222. 0.0505 s / img. ETA=0:02:05\n",
      "\u001b[32m[12/18 17:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 889/3222. 0.0506 s / img. ETA=0:02:00\n",
      "\u001b[32m[12/18 17:29:43 d2.evaluation.evaluator]: \u001b[0mInference done 986/3222. 0.0507 s / img. ETA=0:01:55\n",
      "\u001b[32m[12/18 17:29:48 d2.evaluation.evaluator]: \u001b[0mInference done 1084/3222. 0.0507 s / img. ETA=0:01:50\n",
      "\u001b[32m[12/18 17:29:53 d2.evaluation.evaluator]: \u001b[0mInference done 1180/3222. 0.0507 s / img. ETA=0:01:45\n",
      "\u001b[32m[12/18 17:29:58 d2.evaluation.evaluator]: \u001b[0mInference done 1276/3222. 0.0508 s / img. ETA=0:01:40\n",
      "\u001b[32m[12/18 17:30:03 d2.evaluation.evaluator]: \u001b[0mInference done 1373/3222. 0.0508 s / img. ETA=0:01:35\n",
      "\u001b[32m[12/18 17:30:08 d2.evaluation.evaluator]: \u001b[0mInference done 1471/3222. 0.0508 s / img. ETA=0:01:30\n",
      "\u001b[32m[12/18 17:30:13 d2.evaluation.evaluator]: \u001b[0mInference done 1573/3222. 0.0506 s / img. ETA=0:01:25\n",
      "\u001b[32m[12/18 17:30:18 d2.evaluation.evaluator]: \u001b[0mInference done 1671/3222. 0.0506 s / img. ETA=0:01:19\n",
      "\u001b[32m[12/18 17:30:23 d2.evaluation.evaluator]: \u001b[0mInference done 1769/3222. 0.0506 s / img. ETA=0:01:14\n",
      "\u001b[32m[12/18 17:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 1865/3222. 0.0506 s / img. ETA=0:01:09\n",
      "\u001b[32m[12/18 17:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 1961/3222. 0.0506 s / img. ETA=0:01:05\n",
      "\u001b[32m[12/18 17:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 2055/3222. 0.0507 s / img. ETA=0:01:00\n",
      "\u001b[32m[12/18 17:30:43 d2.evaluation.evaluator]: \u001b[0mInference done 2152/3222. 0.0507 s / img. ETA=0:00:55\n",
      "\u001b[32m[12/18 17:30:48 d2.evaluation.evaluator]: \u001b[0mInference done 2249/3222. 0.0507 s / img. ETA=0:00:50\n",
      "\u001b[32m[12/18 17:30:53 d2.evaluation.evaluator]: \u001b[0mInference done 2345/3222. 0.0507 s / img. ETA=0:00:45\n",
      "\u001b[32m[12/18 17:30:58 d2.evaluation.evaluator]: \u001b[0mInference done 2440/3222. 0.0508 s / img. ETA=0:00:40\n",
      "\u001b[32m[12/18 17:31:03 d2.evaluation.evaluator]: \u001b[0mInference done 2538/3222. 0.0508 s / img. ETA=0:00:35\n",
      "\u001b[32m[12/18 17:31:08 d2.evaluation.evaluator]: \u001b[0mInference done 2634/3222. 0.0508 s / img. ETA=0:00:30\n",
      "\u001b[32m[12/18 17:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 2731/3222. 0.0508 s / img. ETA=0:00:25\n",
      "\u001b[32m[12/18 17:31:18 d2.evaluation.evaluator]: \u001b[0mInference done 2829/3222. 0.0508 s / img. ETA=0:00:20\n",
      "\u001b[32m[12/18 17:31:23 d2.evaluation.evaluator]: \u001b[0mInference done 2925/3222. 0.0508 s / img. ETA=0:00:15\n",
      "\u001b[32m[12/18 17:31:28 d2.evaluation.evaluator]: \u001b[0mInference done 3019/3222. 0.0508 s / img. ETA=0:00:10\n",
      "\u001b[32m[12/18 17:31:33 d2.evaluation.evaluator]: \u001b[0mInference done 3116/3222. 0.0508 s / img. ETA=0:00:05\n",
      "\u001b[32m[12/18 17:31:38 d2.evaluation.evaluator]: \u001b[0mInference done 3210/3222. 0.0509 s / img. ETA=0:00:00\n",
      "\u001b[32m[12/18 17:31:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:46.919078 (0.051887 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/18 17:31:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:43 (0.050868 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/18 17:31:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/18 17:31:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[12/18 17:31:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.46s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 1.46 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.39 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.460\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.515\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.581\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675\n",
      "\u001b[32m[12/18 17:31:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.523 | 46.041 | 22.137 | 10.922 | 51.480 | 60.463 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 23.523482945037163,\n",
       "               'AP50': 46.04143818044157,\n",
       "               'AP75': 22.13662667306016,\n",
       "               'APs': 10.922065542102427,\n",
       "               'APm': 51.48030704738243,\n",
       "               'APl': 60.46302256891186})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, 'model_final.pth')\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.85\n",
    "\n",
    "evaluator = COCOEvaluator('widerface_val', cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"widerface_val\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, 'model_final.pth')\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.7\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "metadata = MetadataCatalog.get(\"widerface_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/idealabs/data/opensource_dataset/WIDER/test/images/0--Parade/\"\n",
    "for _ in glob.glob(image_path+\"/*.jpg\"):\n",
    "    img = cv2.imread(_)\n",
    "    outputs = predictor(img)\n",
    "    v = Visualizer(\n",
    "        img[:, :, ::-1],\n",
    "        metadata=metadata,\n",
    "        scale=1,\n",
    "        instance_mode=ColorMode.IMAGE\n",
    "    )\n",
    "    instances = outputs['instances'].to('cpu')\n",
    "    out = v.draw_instance_predictions(instances)\n",
    "    cv2.imshow(\"out\", out.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
